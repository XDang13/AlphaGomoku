{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from basic_conv2d import BasicConv2d\n",
    "\n",
    "__all__ = [\"InceptionBlockA\", \"InceptionBlockB\", \"InceptionBlockC\",\n",
    "           \"InceptionBlockD\", \"InceptionBlockE\", \"InceptionV3\", \"build_inceptionv3\"]\n",
    "\n",
    "class InceptionBlockA(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockA, self).__init__()\n",
    "        self.block_1x1 = BasicConv2d(in_channels, 64, kernel_size=1, active_fn=active_fn)\n",
    "\n",
    "        self.block_5x5 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 48, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(48, 64, kernel_size=5, padding=2, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_3x3dbl = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 64, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(64, 96, kernel_size=3, padding=1, active_fn=active_fn),\n",
    "            BasicConv2d(96, 96, kernel_size=3, padding=1, active_fn=active_fn),\n",
    "        )\n",
    "\n",
    "        self.block_pool = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, pool_features, kernel_size=1, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        block_1x1_output = self.block_1x1(x)\n",
    "\n",
    "        block_5x5_output = self.block_5x5(x)\n",
    "\n",
    "        block_3x3dbl_output = self.block_3x3dbl(x)\n",
    "        \n",
    "        block_pool_output = self.block_pool(x)\n",
    "\n",
    "        outputs = [block_1x1_output, block_5x5_output, block_3x3dbl_output, block_pool_output]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionBlockB(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockB, self).__init__()\n",
    "        self.block_3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2, active_fn=nn.ReLU(True))\n",
    "\n",
    "        self.block_3x3dbl = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 64, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(64, 96, kernel_size=3, padding=1, active_fn=active_fn),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=2, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_3x3_output = self.block_3x3(x)\n",
    "\n",
    "        block_3x3dbl_output = self.block_3x3dbl(x)\n",
    "\n",
    "        block_pool_output = self.block_pool(x)\n",
    "\n",
    "        outputs = [block_3x3_output, block_3x3dbl_output, block_pool_output]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionBlockC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, channels_7x7, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockC, self).__init__()\n",
    "        self.block_1x1 = BasicConv2d(in_channels, 192, kernel_size=1, active_fn=active_fn)\n",
    "        \n",
    "        \n",
    "        self.block_7x7 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, channels_7x7, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, channels_7x7, kernel_size=(1, 7), padding=(0, 3), active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, 192, kernel_size=(7, 1), padding=(3, 0), active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_7x7bdl = nn.Sequential(\n",
    "            BasicConv2d(in_channels, channels_7x7, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, channels_7x7, kernel_size=(7, 1), padding=(3, 0), active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, channels_7x7, kernel_size=(1, 7), padding=(0, 3), active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, channels_7x7, kernel_size=(7, 1), padding=(3, 0), active_fn=active_fn),\n",
    "            BasicConv2d(channels_7x7, 192, kernel_size=(1, 7), padding=(0, 3), active_fn=active_fn),\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        self.block_pool = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1, active_fn=active_fn),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_1x1_output = self.block_1x1(x)\n",
    "\n",
    "        block_7x7_output = self.block_7x7(x)\n",
    "\n",
    "        block_7x7bdl_output = self.block_7x7bdl(x)\n",
    "\n",
    "        block_pool_output = self.block_pool(x)\n",
    "\n",
    "        outputs = [block_1x1_output, block_7x7_output, block_7x7bdl_output, block_pool_output]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionBlockD(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockD, self).__init__()\n",
    "        self.block_3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(192, 320, kernel_size=3, stride=2, active_fn=active_fn),\n",
    "        )\n",
    "\n",
    "        self.block_7x7x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3), active_fn=active_fn),\n",
    "            BasicConv2d(192, 192, kernel_size=(7, 1), padding=(3, 0), active_fn=active_fn),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=2, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_3x3_output = self.block_3x3(x)\n",
    "\n",
    "        block_7x7x3_output = self.block_7x7x3(x)\n",
    "        \n",
    "\n",
    "        block_pool_output = self.block_pool(x)\n",
    "        outputs = [block_3x3_output, block_7x7x3_output, block_pool_output]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionBlockE(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockE, self).__init__()\n",
    "        self.block_1x1 = BasicConv2d(in_channels, 320,\n",
    "                                     kernel_size=1, active_fn=active_fn)\n",
    "\n",
    "        self.block_3x3 = BasicConv2d(in_channels, 384, kernel_size=1, active_fn=active_fn)\n",
    "            \n",
    "        self.block_3x3_list = nn.ModuleList(\n",
    "            [\n",
    "                BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1), active_fn=active_fn), \n",
    "                BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0), active_fn=active_fn),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.block_3x3dbl = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 448, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(448, 384, kernel_size=3, padding=1, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_3x3dbl_list = nn.ModuleList(\n",
    "            [\n",
    "                BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1), active_fn=active_fn),\n",
    "                BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0), active_fn=active_fn),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.block_pool = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1, active_fn=active_fn),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_1x1_ouput = self.block_1x1(x)\n",
    "\n",
    "        block_3x3_ouput = self.block_3x3(x)\n",
    "        block_3x3_ouput = torch.cat([layer(block_3x3_ouput) for layer in self.block_3x3_list],\n",
    "                                    1)\n",
    "\n",
    "        block_3x3dbl_output = self.block_3x3dbl(x)\n",
    "                \n",
    "        block_3x3dbl_output = torch.cat([layer(block_3x3dbl_output) for layer in self.block_3x3dbl_list],\n",
    "                                 1)\n",
    "        block_pool_output = self.block_pool(x)\n",
    "\n",
    "        outputs = [block_1x1_ouput, block_3x3_ouput, block_3x3dbl_output, block_pool_output]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionBlockAux(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionBlockAux, self).__init__()\n",
    "        self.block_pool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.block_1 = BasicConv2d(in_channels, 128, kernel_size=1, active_fn=active_fn)\n",
    "        self.block_2 = BasicConv2d(128, 768, kernel_size=5, active_fn=active_fn)\n",
    "        self.block_2.stddev = 0.01\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.fc.stddev = 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.block_pool(x)\n",
    "        output = self.block_1(output)\n",
    "        output = self.block_2(output)\n",
    "        \n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Basebone(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, aux_logits=True, active_fn=nn.ReLU(True)):\n",
    "        super(InceptionV3Basebone, self).__init__()\n",
    "        \n",
    "        self.aux_logits = aux_logits\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2, active_fn=active_fn),\n",
    "            BasicConv2d(32, 32, kernel_size=3, active_fn=active_fn),\n",
    "            BasicConv2d(32, 64, kernel_size=3, padding=1, active_fn=active_fn),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.block_2 = nn.Sequential(\n",
    "            BasicConv2d(64, 80, kernel_size=1, active_fn=active_fn),\n",
    "            BasicConv2d(80, 192, kernel_size=3, active_fn=active_fn),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.block_3 = nn.Sequential(\n",
    "            InceptionBlockA(192, pool_features=32, active_fn=active_fn),\n",
    "            InceptionBlockA(256, pool_features=64, active_fn=active_fn),\n",
    "            InceptionBlockA(288, pool_features=64, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "        self.block_4 = nn.Sequential(\n",
    "            InceptionBlockB(288, active_fn=active_fn),\n",
    "            InceptionBlockC(768, channels_7x7=128, active_fn=active_fn),\n",
    "            InceptionBlockC(768, channels_7x7=160, active_fn=active_fn),\n",
    "            InceptionBlockC(768, channels_7x7=160, active_fn=active_fn),\n",
    "            InceptionBlockC(768, channels_7x7=192, active_fn=active_fn),\n",
    "        )\n",
    "            \n",
    "        self.block_5 = nn.Sequential(\n",
    "            InceptionBlockD(768, active_fn=active_fn),\n",
    "            InceptionBlockE(1280, active_fn=active_fn),\n",
    "            InceptionBlockE(2048, active_fn=active_fn),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.block_1(x)\n",
    "        output = self.block_2(output)\n",
    "        output = self.block_3(output)\n",
    "        output = self.block_4(output)\n",
    "        if self.training and self.aux_logits:\n",
    "            aux = output\n",
    "\n",
    "        output = self.block_5(output)\n",
    "        output = self.block_pool(output)\n",
    "\n",
    "        if self.training and self.aux_logits:\n",
    "            return output, aux\n",
    "\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def to_list(self):\n",
    "        return [self.block_1, self.block_2, self.block_3,\n",
    "                self.block_4, self.block_5]\n",
    "\n",
    "    @property\n",
    "    def to_sequential(self):\n",
    "        return nn.Sequential(*self.to_list)\n",
    "\n",
    "    @property\n",
    "    def to_modellist(self):\n",
    "        return nn.ModuleList(self.to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, num_classes=1000, aux_logits=True,\n",
    "                 active_fn=nn.ReLU(True)):\n",
    "        super(InceptionV3, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        \n",
    "        self.feature_block = InceptionV3Basebone(in_channels, aux_logits, active_fn)\n",
    "        \n",
    "        if self.aux_logits:\n",
    "            self.block_aux = InceptionBlockAux(768, num_classes, active_fn=active_fn)\n",
    "        \n",
    "        self.block_pool = nn.AvgPool2d(kernel_size=8)\n",
    "        \n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.aux_logits:\n",
    "            output, aux = self.feature_block(x)\n",
    "            aux = self.block_aux(aux)\n",
    "        else:\n",
    "            output = self.feature_block(x)\n",
    "        \n",
    "        output = F.dropout(output, training=self.training)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        if self.training and self.aux_logits:\n",
    "            return output, aux\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_feature_block(self, mode=\"list\"):\n",
    "        \n",
    "        assert mode in [\"list\", \"seq\", \"model_list\"]\n",
    "        \n",
    "        blocks = [self.block_1, self.block_2, self.block_3,\n",
    "                  self.block_4, self.block_5]\n",
    "        if mode == \"list\":\n",
    "            layers = blocks\n",
    "            return layers\n",
    "        elif mode == \"seq\":\n",
    "            layers = nn.Sequential(*blocks)\n",
    "            return layers\n",
    "        elif mode == \"model_list\":\n",
    "            layers = nn.ModuleList(blocks)\n",
    "            return layers\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def build_inceptionv3(pretrained=False, **kwargs):\n",
    "    \n",
    "    model = InceptionV3(**kwargs)\n",
    "    if pretrained:\n",
    "        pass\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = InceptionV3Basebone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(4,3,299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-22d29d5af2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
